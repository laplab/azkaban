{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "from pandas import ewma\n",
    "\n",
    "def plot_stats(data, name):\n",
    "    plt.grid()\n",
    "    plt.plot(data, label=name, alpha=0.2)\n",
    "    plt.plot(ewma(np.array(data), span=10), label='{} ewma@10'.format(name), alpha=0.5)\n",
    "    plt.plot(ewma(np.array(data), span=100), label='{} ewma@100'.format(name))\n",
    "    plt.title('{} survivors'.format(name))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class A3CModel(nn.Module):\n",
    "    def __init__(self, in_channels, n_actions):\n",
    "        super(A3CModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(27, 256)\n",
    "        \n",
    "        self.logits = nn.Linear(256, n_actions)\n",
    "        self.state_value = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        middle = tuple(ax // 2 for ax in obs[0].shape)\n",
    "\n",
    "        state = np.stack(\n",
    "            (obs[0] == obs[0][middle], obs[1], obs[2]),\n",
    "            axis=-1\n",
    "        ).flatten().astype(float)\n",
    "        x = Variable(torch.FloatTensor(state).unsqueeze(0))\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        logits = self.logits(x)\n",
    "        state_value = self.state_value(x)\n",
    "        \n",
    "        return logits, state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azkaban.agent import RandomAgent, A3CAgent, A3CParams\n",
    "from azkaban.env import TeamsEnv, TeamsEnvConf\n",
    "from azkaban.optim import SharedAdam\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch.multiprocessing import Lock\n",
    "\n",
    "conf = TeamsEnvConf(\n",
    "    world_shape=(7, 7),\n",
    "    comm_shape=(0,),\n",
    "    team_names=[\n",
    "        'a3c',\n",
    "        'random'\n",
    "    ]\n",
    ")\n",
    "\n",
    "def model_generator():\n",
    "    return A3CModel(\n",
    "        in_channels=3,\n",
    "        n_actions=conf.action_space.shape()[0]\n",
    "    )\n",
    "\n",
    "params = A3CParams()\n",
    "\n",
    "shared_model = model_generator()\n",
    "shared_optimizer = SharedAdam(shared_model.parameters(), lr=params.lr)\n",
    "shared_lock = Lock()\n",
    "\n",
    "a3c_team = 5\n",
    "random_team = 5\n",
    "\n",
    "def env_generator():\n",
    "    return TeamsEnv(\n",
    "        teams=[\n",
    "            tuple(\n",
    "                A3CAgent(\n",
    "                    conf=conf,\n",
    "                    params=params,\n",
    "                    model=model_generator(),\n",
    "                    shared_model=shared_model,\n",
    "                    shared_optimizer=shared_optimizer,\n",
    "                    trainable=True,\n",
    "                    lock=shared_lock\n",
    "                ) for i in range(a3c_team)\n",
    "            ),\n",
    "            tuple(\n",
    "                RandomAgent(\n",
    "                    conf=conf\n",
    "                ) for i in range(random_team)\n",
    "            )\n",
    "        ],\n",
    "        conf=conf\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "stats_lock = Lock()\n",
    "stats = []\n",
    "\n",
    "max_ticks = 1000\n",
    "\n",
    "def worker():\n",
    "    env = env_generator()\n",
    "    \n",
    "    while True:\n",
    "        env.reset()\n",
    "        \n",
    "        for i in range(max_ticks):\n",
    "            done = env.step(interrupt=(i == max_ticks - 1))\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        print('!')\n",
    "        with stats_lock:\n",
    "            print('?')\n",
    "            stats.append(tuple(copy(env.members)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/laplab/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/laplab/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: 'Process' object is not callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Ctrl+C to exit\n"
     ]
    }
   ],
   "source": [
    "from torch.multiprocessing import Process\n",
    "import time\n",
    "\n",
    "n_workers = 1\n",
    "workers = []\n",
    "\n",
    "for _ in range(n_workers):\n",
    "    p = Process(target=worker)\n",
    "    p.start()\n",
    "    workers.append(p)\n",
    "\n",
    "print('Press Ctrl+C to exit')\n",
    "try:\n",
    "    time.sleep(1)\n",
    "    \n",
    "    clear_output(True)\n",
    "    \n",
    "    if len(stats) > 0:\n",
    "        with stats_lock:\n",
    "            a3c, random = zip(*stats)\n",
    "\n",
    "        plt.figure(figsize=(16, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_stats(a3c, name='a3c')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_stats(random, name='random')\n",
    "        plt.savefig('results.png')\n",
    "        plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    print('Killing workers...')\n",
    "    \n",
    "    for worker in workers:\n",
    "        worker.terminate()\n",
    "    \n",
    "    shared_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker in workers:\n",
    "    worker.terminate()\n",
    "shared_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
